{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ecoILP import load_model, handleEdgeList, extractFeatures, predictLinks, plotMetrics, plotProbsMatrix\n",
    "\n",
    "# Force reload modules each execution\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks_list = ['1982.csv', '1983.csv', '1984.csv', '1985.csv', '1986.csv', '1987.csv']\n",
    "\n",
    "# Load all networks\n",
    "networks = [pd.read_csv(f'data/raw/networks/case_study/{network}', index_col=0, header=0) for network in networks_list]\n",
    "\n",
    "# Convert to edge list\n",
    "edgeLists = [network.stack().rename_axis(['lower_level','higher_level']).rename('weight').reset_index() for network in networks]\n",
    "\n",
    "# Add year column\n",
    "for i, year in enumerate(networks_list):\n",
    "    edgeLists[i]['year'] = year.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "\n",
    "for edgeList in edgeLists:\n",
    "\n",
    "    dataframe = handleEdgeList(\n",
    "        edgeList, \n",
    "        linkID_col = None, # If the edge list doesn't have a column for link ID, it will be created\n",
    "        topNodes_col = 'higher_level', \n",
    "        bottomNodes_col = 'lower_level', \n",
    "        networkID_col = 'year', # If the edge list doesn't have a column for network ID, a dummy value will be created\n",
    "        groupID_col = None,\n",
    "        weight_col = 'weight', # currently support only binary values though\n",
    "        community = 'Host-Parasite', # in case the community is known but not in the groupID_col\n",
    "        sample_fraction = 0.2, # fraction of missing links to create\n",
    "        # missing_links = sample_network[sample_network['class'] == -1]['link_ID'], # if the missing links are predefined\n",
    "        # groundTruth_col = 'class'\n",
    "        )\n",
    "\n",
    "    dataframe_with_features = extractFeatures(dataframe)\n",
    "    \n",
    "    probabilities, classifications = predictLinks(dataframe_with_features, model)\n",
    "\n",
    "    plotMetrics(\n",
    "        dataframe_with_features,\n",
    "        probabilities, \n",
    "        plots=['confusion_matrix', 'single_evaluation', 'roc_curve', 'pr_curve', 'probs_distribution']\n",
    "        )\n",
    "\n",
    "    # plotProbsMatrix(dataframe, probabilities, figsize=(14,8))\n",
    "    \n",
    "    result = pd.concat([\n",
    "        dataframe.rename(columns={'name': 'year'}).drop(columns=['weight'], axis=1), \n",
    "        pd.DataFrame(probabilities, columns=['y_proba']),\n",
    "        pd.DataFrame(classifications, columns=['y_pred'])\n",
    "        ], axis=1)\n",
    "    \n",
    "    output.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.concat(output, ignore_index=True)\n",
    "\n",
    "output.to_csv('results/intermediate/case_study.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
