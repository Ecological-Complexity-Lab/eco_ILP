{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base\n",
    "import os\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None) # turn off some annoying warnings\n",
    "\n",
    "# Number of avialable cores\n",
    "nslots = int(os.getenv('NSLOTS', 2))\n",
    "print('cores:' ,nslots, ', dir:', os.getcwd()) # should be '/gpfs0/shai/users/barryb/link-predict'\n",
    "\n",
    "# Force reload modules each execution\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load custom modules\n",
    "from helper.ml_class import LinkPredict\n",
    "from helper.custom_cv import CustomGroupCV, CustomGroupSplit\n",
    "from helper.base import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe\n",
    "meta, df_initial = load_data(\n",
    "    path_meta = 'data/processed/networks/subsamples_metadata.csv',\n",
    "    path_subsample = 'data/processed/networks/subsamples_edge_lists.csv',\n",
    "    paths_features = ['data/processed/features/features_py.csv',\n",
    "                      'data/processed/features/features_R.csv'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save results\n",
    "results_path = 'results/'\n",
    "\n",
    "# Columns to ignore during training\n",
    "columns_ignore = ['name', 'link_ID', 'subsample_ID', 'fraction', 'repetition', 'higher_level', 'lower_level', 'weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_initial.copy()\n",
    "\n",
    "# Drop features\n",
    "to_drop = ['flow_infomap_HL', 'flow_infomap_LL', 'modular_centrality_infomap_HL', 'modular_centrality_infomap_LL']\n",
    "df = df.drop(to_drop, axis=1)\n",
    "\n",
    "df['Fisher alpha'] = df['Fisher alpha'].astype('float64')\n",
    "\n",
    "# TODO: Change this in the first step as it is confusing\n",
    "df['class'] = df['class'].astype('int64')\n",
    "\n",
    "# Move 'class' to the end\n",
    "df = df[[c for c in df if c not in ['class']] + ['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgs = CustomGroupSplit(group_by='name', \n",
    "                       stratify_by='community', \n",
    "                       fractions_col = 'fraction',\n",
    "                       train_size=0.7, \n",
    "                       undersample_ratio=None,\n",
    "                       fractions_train = [1],\n",
    "                       fractions_test = [0.8], \n",
    "                       groups_train = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "                       groups_test = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "                       drop_isolates=False,\n",
    "                       drop_existing_links = True,\n",
    "                       keep_fractions_train=True, # Keep all fractions in train, although they are in fractions_train (will needed later)\n",
    "                       keep_fractions_test=False,\n",
    "                       random_state=42,\n",
    "                       )\n",
    "\n",
    "train_idx, test_idx  = next(cgs.split(df))\n",
    "train_link_id, test_link_id  = cgs.get_link_ids(0)\n",
    "\n",
    "X_train, y_train = LinkPredict().subset_data(df, train_link_id, cast_target=False)\n",
    "X_test, y_test = LinkPredict().subset_data(df, test_link_id, cast_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgc_inner = CustomGroupCV(\n",
    "    group_by='name', \n",
    "    stratify_by='community', \n",
    "    fractions_col = 'fraction',\n",
    "    n_splits = 3,\n",
    "    fractions_train = [1],\n",
    "    fractions_test = [0.8],\n",
    "    groups_train = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "    groups_test = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "    drop_isolates=False,\n",
    "    drop_existing_links = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgc_outer = CustomGroupCV(\n",
    "    group_by='name', \n",
    "    stratify_by='community', \n",
    "    fractions_col = 'fraction',\n",
    "    n_splits = 5,\n",
    "    fractions_train = [1],\n",
    "    fractions_test = [0.8],\n",
    "    groups_train = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "    groups_test = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "    drop_isolates=False,\n",
    "    drop_existing_links = True,\n",
    "    keep_fractions_train=True, # Keep all fractions in train, although they are in fractions_train (will needed later)\n",
    "    keep_fractions_test=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test split + Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml = LinkPredict('RandomForestClassifier')\n",
    "\n",
    "# ml.fit(X_train,\n",
    "#        y_train,\n",
    "#        cv=cgc_outer,\n",
    "#        class_weight='balanced',\n",
    "#        tuner_name='RandomizedSearchCV',\n",
    "#        columns_to_ignore=columns_ignore)\n",
    "\n",
    "# ml.multi_plot(X_test, y_test, threshold=0.5, \n",
    "#     plots=['confusion_matrix', 'grouped_evaluation', 'roc_curve', 'pr_curve', 'probs_distribution', 'roc_curve_split', 'pr_curve_split', 'grouped_evaluation_split', 'feature_importance'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml = LinkPredict('RandomForestClassifier')\n",
    "# X, y = LinkPredict().subset_data(df, cast_target=False)\n",
    "\n",
    "# ml.fit(X,\n",
    "#        y,\n",
    "#        cv_inner=cgc_inner,\n",
    "#        cv_outer=cgc_outer, # Nested cross-validation\n",
    "#        class_weight='balanced',\n",
    "#        tuner_name='RandomizedSearchCV',\n",
    "#        columns_to_ignore=columns_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save results\n",
    "# results_df = pd.DataFrame({'fold':[]})\n",
    "# results_link_ids = cgc_outer.get_link_ids()[1]\n",
    "\n",
    "# for fold in range(cgc_outer.get_n_splits()):\n",
    "    \n",
    "#     test_links = results_link_ids[fold]\n",
    "#     X_test_subset = X[X['link_ID'].isin(test_links)]#.drop(['community'], axis=1)\n",
    "#     ml.set_fold_model(fold)\n",
    "    \n",
    "#     y_proba = ml.predict_proba(X_test_subset)\n",
    "#     df_len = len(y_proba)\n",
    "#     results_fold_df = pd.DataFrame({\n",
    "#         'fold':[fold]*df_len, \n",
    "#         'link_ID':X_test_subset['link_ID'],\n",
    "#         'type_train':[cgc_outer.groups_train]*df_len,\n",
    "#         'type_test':[cgc_outer.groups_test]*df_len,\n",
    "#         'frac_train':[cgc_outer.fractions_train]*df_len,\n",
    "#         'frac_test':[cgc_outer.fractions_test]*df_len,\n",
    "#         'model':[ml.model_name]*df_len,\n",
    "#         'y_proba':y_proba,\n",
    "#     })\n",
    "#     results_df = pd.concat([results_df, results_fold_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.to_csv(results_path+'/raw/results_nested_cv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare all community types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Set netwrok types\n",
    "network_types = communities = [\n",
    "    'Host-Parasite', 'Plant-Pollinator', 'Plant-Seed Dispersers', 'Plant-Herbivore',\n",
    "]\n",
    "\n",
    "# Create combinations of network types for training and testing\n",
    "types_combinations = []\n",
    "for i in [1]: # remove last arg for all combs\n",
    "    types_combinations += list(combinations(network_types, i))\n",
    "\n",
    "types_combinations += [('Plant-Seed Dispersers', 'Plant-Pollinator', 'Plant-Herbivore', 'Host-Parasite')] # Ecological\n",
    "types_combinations+= [('Plant-Seed Dispersers', 'Plant-Herbivore', 'Host-Parasite')] # Ecological-Non-Plant-Pollinator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models_types=[]\n",
    "cgc_list = []\n",
    "\n",
    "X, y = LinkPredict().subset_data(df, cast_target=False)\n",
    "\n",
    "for types_train in types_combinations:\n",
    "    for types_test in types_combinations:\n",
    "        \n",
    "        print('Type train:', types_train, '\\nType test:', types_test, '\\n')\n",
    "        \n",
    "        cgc_inner = CustomGroupCV(\n",
    "            group_by='name', \n",
    "            stratify_by='community', \n",
    "            fractions_col = 'fraction',\n",
    "            n_splits = 3,\n",
    "            fractions_train = [1],\n",
    "            fractions_test = [0.8],\n",
    "            groups_train = types_train,\n",
    "            groups_test = types_train,\n",
    "            drop_isolates=False,\n",
    "            drop_existing_links = True\n",
    "            )\n",
    "\n",
    "        cgc_outer = CustomGroupCV(\n",
    "            group_by='name', \n",
    "            stratify_by='community', \n",
    "            fractions_col = 'fraction',\n",
    "            n_splits = 5,\n",
    "            fractions_train = [1],\n",
    "            fractions_test = [0.8],\n",
    "            groups_train = types_train,\n",
    "            groups_test = types_test,\n",
    "            drop_isolates=False,\n",
    "            drop_existing_links = True,\n",
    "            keep_fractions_train=True, # Keep all fractions in train, although they are in fractions_train (will needed later)\n",
    "            keep_fractions_test=False\n",
    "            )\n",
    "\n",
    "        ml = LinkPredict('RandomForestClassifier')\n",
    "\n",
    "        # Train\n",
    "        ml.fit(X,\n",
    "            y,\n",
    "            cv_inner=cgc_inner,\n",
    "            cv_outer=cgc_outer,\n",
    "            scorer_metric='f1',\n",
    "            class_weight='balanced',\n",
    "            tuner_name='RandomizedSearchCV',\n",
    "            columns_to_ignore=columns_ignore)\n",
    "\n",
    "        # Save model\n",
    "        ml.types_train = types_train\n",
    "        ml.types_test = types_test\n",
    "        trained_models_types.append(ml) \n",
    "        cgc_list.append(cgc_outer)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df = pd.DataFrame() #{'fold':[]}\n",
    "\n",
    "for ml, cgc_outer in zip(trained_models_types, cgc_list):\n",
    "\n",
    "    results_link_ids = cgc_outer.get_link_ids()[1]\n",
    "\n",
    "    for fold in range(cgc_outer.get_n_splits()):\n",
    "\n",
    "        test_links = results_link_ids[fold]\n",
    "        X_test_subset = X[X['link_ID'].isin(test_links)]\n",
    "        ml.set_fold_model(fold)\n",
    "        \n",
    "        y_proba = ml.predict_proba(X_test_subset)\n",
    "        df_len = len(y_proba)\n",
    "        results_run_df = pd.DataFrame({\n",
    "            'fold':[fold]*df_len, \n",
    "            'link_ID':X_test_subset['link_ID'],\n",
    "            'type_train':[list(cgc_outer.groups_train)]*df_len,\n",
    "            'type_test':[list(cgc_outer.groups_test)]*df_len,\n",
    "            # 'frac_train':[cgc_outer.fractions_train]*df_len,\n",
    "            # 'frac_test':[cgc_outer.fractions_test]*df_len,\n",
    "            # 'model':[ml.model_name]*df_len,\n",
    "            'y_proba':y_proba,\n",
    "        })\n",
    "        results_df = pd.concat([results_df, results_run_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(results_path+'/raw/results_domains_F1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new: for balanced accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models_types_BA=[]\n",
    "cgc_list_BA = []\n",
    "\n",
    "X, y = LinkPredict().subset_data(df, cast_target=False)\n",
    "\n",
    "for types_train in types_combinations:\n",
    "    for types_test in types_combinations:\n",
    "        \n",
    "        print('Type train:', types_train, '\\nType test:', types_test, '\\n')\n",
    "        \n",
    "        cgc_inner = CustomGroupCV(\n",
    "            group_by='name', \n",
    "            stratify_by='community', \n",
    "            fractions_col = 'fraction',\n",
    "            n_splits = 3,\n",
    "            fractions_train = [1],\n",
    "            fractions_test = [0.8],\n",
    "            groups_train = types_train,\n",
    "            groups_test = types_train,\n",
    "            drop_isolates=False,\n",
    "            drop_existing_links = True\n",
    "            )\n",
    "\n",
    "        cgc_outer = CustomGroupCV(\n",
    "            group_by='name', \n",
    "            stratify_by='community', \n",
    "            fractions_col = 'fraction',\n",
    "            n_splits = 5,\n",
    "            fractions_train = [1],\n",
    "            fractions_test = [0.8],\n",
    "            groups_train = types_train,\n",
    "            groups_test = types_test,\n",
    "            drop_isolates=False,\n",
    "            drop_existing_links = True,\n",
    "            keep_fractions_train=True, # Keep all fractions in train, although they are in fractions_train (will needed later)\n",
    "            keep_fractions_test=False\n",
    "            )\n",
    "\n",
    "        ml = LinkPredict('RandomForestClassifier')\n",
    "\n",
    "        # Train\n",
    "        ml.fit(X,\n",
    "            y,\n",
    "            cv_inner=cgc_inner,\n",
    "            cv_outer=cgc_outer,\n",
    "            scorer_metric='balanced_accuracy',\n",
    "            class_weight='balanced',\n",
    "            tuner_name='RandomizedSearchCV',\n",
    "            columns_to_ignore=columns_ignore)\n",
    "\n",
    "        # Save model\n",
    "        ml.types_train = types_train\n",
    "        ml.types_test = types_test\n",
    "        trained_models_types_BA.append(ml) \n",
    "        cgc_list_BA.append(cgc_outer)\n",
    "        \n",
    "# Save results\n",
    "results_df = pd.DataFrame() #{'fold':[]}\n",
    "\n",
    "for ml, cgc_outer in zip(trained_models_types_BA, cgc_list_BA):\n",
    "\n",
    "    results_link_ids = cgc_outer.get_link_ids()[1]\n",
    "\n",
    "    for fold in range(cgc_outer.get_n_splits()):\n",
    "\n",
    "        test_links = results_link_ids[fold]\n",
    "        X_test_subset = X[X['link_ID'].isin(test_links)]\n",
    "        ml.set_fold_model(fold)\n",
    "        \n",
    "        y_proba = ml.predict_proba(X_test_subset)\n",
    "        df_len = len(y_proba)\n",
    "        results_run_df = pd.DataFrame({\n",
    "            'fold':[fold]*df_len, \n",
    "            'link_ID':X_test_subset['link_ID'],\n",
    "            'type_train':[list(cgc_outer.groups_train)]*df_len,\n",
    "            'type_test':[list(cgc_outer.groups_test)]*df_len,\n",
    "            # 'frac_train':[cgc_outer.fractions_train]*df_len,\n",
    "            # 'frac_test':[cgc_outer.fractions_test]*df_len,\n",
    "            # 'model':[ml.model_name]*df_len,\n",
    "            'y_proba':y_proba,\n",
    "        })\n",
    "        results_df = pd.concat([results_df, results_run_df], axis=0)\n",
    "\n",
    "results_df.to_csv(results_path+'/raw/results_domains_BA.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare ML algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting important variables\n",
    "communities = ['Host-Parasite', 'Plant-Pollinator', 'Plant-Seed Dispersers', 'Plant-Herbivore']\n",
    "classifiers = ['RandomForestClassifier', 'LogisticRegression', 'XGBClassifier']\n",
    "\n",
    "# Store trained models in a list\n",
    "trained_models_algos=[]\n",
    "cgc_list = []\n",
    "\n",
    "# Iterate over classifiers\n",
    "for clf_name in classifiers:\n",
    "\n",
    "   print('Classifier:', clf_name)\n",
    "    \n",
    "   cgc_inner = CustomGroupCV(\n",
    "      group_by='name', \n",
    "      stratify_by='community', \n",
    "      fractions_col = 'fraction',\n",
    "      n_splits = 3,\n",
    "      fractions_train = [1],\n",
    "      fractions_test = [0.8],\n",
    "      groups_train = communities,\n",
    "      groups_test = communities,\n",
    "      drop_isolates=False,\n",
    "      drop_existing_links = True,\n",
    "      )\n",
    "\n",
    "   cgc_outer = CustomGroupCV(\n",
    "      group_by='name', \n",
    "      stratify_by='community', \n",
    "      fractions_col = 'fraction',\n",
    "      n_splits = 5,\n",
    "      fractions_train = [1],\n",
    "      fractions_test = [0.8],\n",
    "      groups_train = communities,\n",
    "      groups_test = communities,\n",
    "      drop_isolates=False,\n",
    "      drop_existing_links = True,\n",
    "      keep_fractions_train=True, # Keep all fractions in train, although they are in fractions_train (will needed later)\n",
    "      keep_fractions_test=False\n",
    "      )\n",
    "   \n",
    "   ml = LinkPredict(clf_name) # Initialize model\n",
    "\n",
    "   X, y = LinkPredict().subset_data(df, cast_target=False)\n",
    "   \n",
    "   ml.fit(X,\n",
    "      y,\n",
    "      cv_inner=cgc_inner,\n",
    "      cv_outer=cgc_outer, # Nested cross-validation\n",
    "      class_weight='balanced',\n",
    "      tuner_name='RandomizedSearchCV',\n",
    "      columns_to_ignore=columns_ignore)\n",
    "\n",
    "   trained_models_algos.append(ml) # Save model\n",
    "   cgc_list.append(cgc_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for ml, cgc_outer in zip(trained_models_algos, cgc_list):\n",
    "\n",
    "    results_link_ids = cgc_outer.get_link_ids()[1]\n",
    "\n",
    "    for fold in range(cgc_outer.get_n_splits()):\n",
    "\n",
    "        test_links = results_link_ids[fold]\n",
    "        # X_test_subset = X[X['link_ID'].isin(test_links)]\n",
    "        X_test_subset, y_test_subset = ml.subset_data(df, test_links)\n",
    "        ml.set_fold_model(fold)\n",
    "\n",
    "        y_proba = ml.predict_proba(X_test_subset)\n",
    "        df_len = len(y_proba)\n",
    "\n",
    "        results_run_df = pd.DataFrame({\n",
    "            'fold':[fold]*df_len,\n",
    "            'link_ID':X_test_subset['link_ID'],\n",
    "            'model':[ml.model_name]*df_len,\n",
    "            'y_proba':y_proba,\n",
    "        })\n",
    "\n",
    "        results_df = pd.concat([results_df, results_run_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting\n",
    "voting_df = results_df.groupby(['fold', 'link_ID'])['y_proba'].mean().reset_index() # Compute the mean values\n",
    "voting_df['model'] = 'Voting'\n",
    "results_df = pd.concat([results_df, voting_df], axis=0) # Merge with the original DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(results_path+'/raw/results_models.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "params_df = pd.DataFrame()\n",
    "\n",
    "for ml, cgc_outer in zip(trained_models_algos, cgc_list):\n",
    "    for fold in range(cgc_outer.get_n_splits()):\n",
    "        ml.set_fold_model(fold)\n",
    "\n",
    "        best_params = ml.trained_model.best_params_\n",
    "        params_df = pd.concat([params_df, \n",
    "                               pd.DataFrame({'model':[ml.model_name], \n",
    "                                             'fold':[fold], \n",
    "                                             'params':[best_params], \n",
    "                                             'params_dist':[ml.params_dist]})], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distbribution and best parameters for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to collect data\n",
    "data = {}\n",
    "\n",
    "for ml, cgc_outer in zip(trained_models_algos, cgc_list):\n",
    "    # Initialize a sub-dictionary for each model\n",
    "    model_data = {}\n",
    "    \n",
    "    for fold in range(cgc_outer.get_n_splits()):\n",
    "        ml.set_fold_model(fold)\n",
    "\n",
    "        best_params = ml.trained_model.best_params_\n",
    "        \n",
    "        # Update model_data with fold information for each parameter\n",
    "        for param, best_value in best_params.items():\n",
    "            # Simplify the parameter name by removing 'classifier__'\n",
    "            simple_param = param.replace('classifier__', '')\n",
    "            \n",
    "            if simple_param not in model_data:\n",
    "                model_data[simple_param] = {'model': ml.model_name, 'parameter': simple_param}\n",
    "            \n",
    "            # Adding the best value for each fold\n",
    "            model_data[simple_param][f'best value (fold {fold + 1})'] = best_value\n",
    "\n",
    "    # Add model data to the main data dictionary, handling params_dist separately\n",
    "    for param, values in model_data.items():\n",
    "        # Extract range for this parameter from params_dist (handle both dict and list of dicts)\n",
    "        params_dist = ml.params_dist\n",
    "        if isinstance(params_dist, list):  # If params_dist is a list of dictionaries\n",
    "            ranges = [d.get(param) for d in params_dist if param in d]\n",
    "            param_range = ranges[0] if ranges else 'No range found'  # Default message or handling if no range is found\n",
    "        else:  # If params_dist is a dictionary\n",
    "            param_range = params_dist.get(param, 'No range found')  # Provide a default if the param is not found\n",
    "        \n",
    "        values['range'] = param_range\n",
    "        data[(ml.model_name, param)] = values\n",
    "\n",
    "# Convert the collected data into a DataFrame\n",
    "params_df = pd.DataFrame.from_dict(data, orient='index').reset_index(drop=True)\n",
    "\n",
    "# change the range of the parameter 'feature_selector__k' to 'No range found'\n",
    "params_df.loc[params_df['parameter'] == 'feature_selector__k', 'range'] = '[10, 20, 30, 40, 50, 70]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df.to_csv(results_path+'/raw/params_models.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance_all_df = pd.DataFrame()\n",
    "\n",
    "for fold in range(cgc_outer.get_n_splits()):\n",
    "    for ml in trained_models_algos:\n",
    "        ml.set_fold_model(fold)\n",
    "        feat_importance_df = ml.feature_importance(X_train=X_train).to_frame(ml.model_name).reset_index().rename(columns={'index':'feature'}).melt(id_vars='feature', var_name='model', value_name='importance')\n",
    "        feat_importance_df['fold'] = fold\n",
    "        feat_importance_all_df = pd.concat([feat_importance_all_df, feat_importance_df], axis=0)\n",
    "\n",
    "feat_importance_all_df.reset_index(drop=True).to_csv(results_path+\"/raw/feature_importance_nCV.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing biased sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe\n",
    "meta_h, df_initial_h = load_data(\n",
    "    path_meta = 'data/processed/networks/biased_sampling/highDegBiasSampling_metadata.csv',\n",
    "    path_subsample = 'data/processed/networks/biased_sampling/highDegBiasSampling_edge_lists.csv',\n",
    "    paths_features = ['data/processed/features/biased_sampling/features_highDegBiasSampling_py.csv',\n",
    "                      'data/processed/features/biased_sampling/features_highDegBiasSampling_R.csv'],\n",
    ")\n",
    "\n",
    "# Load dataframe\n",
    "meta_l, df_initial_l = load_data(\n",
    "    path_meta = 'data/processed/networks/biased_sampling/lowDegBiasSampling_metadata.csv',\n",
    "    path_subsample = 'data/processed/networks/biased_sampling/lowDegBiasSampling_edge_lists.csv',\n",
    "    paths_features = ['data/processed/features/biased_sampling/features_lowDegBiasSampling_py.csv',\n",
    "                      'data/processed/features/biased_sampling/features_lowDegBiasSampling_R.csv'],\n",
    ")\n",
    "\n",
    "## Some preprocessing (later I will fix it in previous steps so no preprocessing will be needed)\n",
    "\n",
    "df_h, df_l = df_initial_h.copy(), df_initial_l.copy()\n",
    "\n",
    "to_drop = ['density', 'common_neighbor_centrality', 'shortest_path_length', 'shortest_paths_count', 'flow_infomap_HL', 'flow_infomap_LL', 'modular_centrality_infomap_HL', 'modular_centrality_infomap_LL', 'discrepancy.HL', 'discrepancy.LL']\n",
    "\n",
    "df_list = [df_h, df_l]\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    df_list[i] = df_list[i].drop(to_drop, axis=1, errors='ignore') # Drop features\n",
    "    df_list[i]['Fisher alpha'] = df_list[i]['Fisher alpha'].astype('float64') # Convert Fisher alpha to float\n",
    "    df_list[i]['class'] = df_list[i]['class'].astype('int64')\n",
    "\n",
    "    # Move 'class' to the end\n",
    "    df_list[i] = df_list[i][[c for c in df_list[i] if c not in ['class']] + ['class']]\n",
    "\n",
    "df_h, df_l = df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting and running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgc_inner = CustomGroupCV(\n",
    "    group_by='name', \n",
    "    stratify_by='community', \n",
    "    fractions_col = 'fraction',\n",
    "    n_splits = 3,\n",
    "    fractions_train = [1],\n",
    "    fractions_test = [0.8],\n",
    "    groups_train = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "    groups_test = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "    drop_isolates=False,\n",
    "    drop_existing_links = True,\n",
    "    )\n",
    "\n",
    "cgc_outer = CustomGroupCV(\n",
    "    group_by='name', \n",
    "    stratify_by='community', \n",
    "    fractions_col = 'fraction',\n",
    "    n_splits = 5,\n",
    "    fractions_train = [1],\n",
    "    fractions_test = [0.8],\n",
    "    groups_train = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "    groups_test = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "    drop_isolates=False,\n",
    "    drop_existing_links = True,\n",
    "    keep_fractions_train=True, # Keep all fractions in train, although they are in fractions_train (will needed later)\n",
    "    keep_fractions_test=False\n",
    "    )\n",
    "\n",
    "ml = LinkPredict('RandomForestClassifier')\n",
    "X, y = LinkPredict().subset_data(df_h, cast_target=False)\n",
    "\n",
    "ml.fit(X, y,\n",
    "       cv_inner=cgc_inner,\n",
    "       cv_outer=cgc_outer, # Nested cross-validation\n",
    "       class_weight='balanced',\n",
    "       tuner_name='RandomizedSearchCV',\n",
    "       columns_to_ignore=columns_ignore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df = pd.DataFrame({'fold':[]})\n",
    "results_link_ids = cgc_outer.get_link_ids()[1]\n",
    "\n",
    "for fold in range(cgc_outer.get_n_splits()):\n",
    "    \n",
    "    test_links = results_link_ids[fold]\n",
    "    X_test_subset = X[X['link_ID'].isin(test_links)]#.drop(['community'], axis=1)\n",
    "    ml.set_fold_model(fold)\n",
    "    \n",
    "    y_proba = ml.predict_proba(X_test_subset)\n",
    "    df_len = len(y_proba)\n",
    "    results_fold_df = pd.DataFrame({\n",
    "        'fold':[fold]*df_len, \n",
    "        'link_ID':X_test_subset['link_ID'],\n",
    "        'type_train':[cgc_outer.groups_train]*df_len,\n",
    "        'type_test':[cgc_outer.groups_test]*df_len,\n",
    "        'frac_train':[cgc_outer.fractions_train]*df_len,\n",
    "        'frac_test':[cgc_outer.fractions_test]*df_len,\n",
    "        'model':[ml.model_name]*df_len,\n",
    "        'y_proba':y_proba,\n",
    "    })\n",
    "    results_df = pd.concat([results_df, results_fold_df], axis=0)\n",
    "\n",
    "results_df.to_csv(results_path+'/raw/results_highDegBiasSampling.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgc_inner = CustomGroupCV(\n",
    "    group_by='name', \n",
    "    stratify_by='community', \n",
    "    fractions_col = 'fraction',\n",
    "    n_splits = 3,\n",
    "    fractions_train = [1],\n",
    "    fractions_test = [0.8],\n",
    "    groups_train = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "    groups_test = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "    drop_isolates=False,\n",
    "    drop_existing_links = True,\n",
    "    )\n",
    "\n",
    "cgc_outer = CustomGroupCV(\n",
    "    group_by='name', \n",
    "    stratify_by='community', \n",
    "    fractions_col = 'fraction',\n",
    "    n_splits = 5,\n",
    "    fractions_train = [1],\n",
    "    fractions_test = [0.8],\n",
    "    groups_train = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "    groups_test = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "    drop_isolates=False,\n",
    "    drop_existing_links = True,\n",
    "    keep_fractions_train=True, # Keep all fractions in train, although they are in fractions_train (will needed later)\n",
    "    keep_fractions_test=False\n",
    "    )\n",
    "\n",
    "ml = LinkPredict('RandomForestClassifier')\n",
    "X, y = LinkPredict().subset_data(df_l, cast_target=False)\n",
    "\n",
    "ml.fit(X,\n",
    "       y,\n",
    "       cv_inner=cgc_inner,\n",
    "       cv_outer=cgc_outer, # Nested cross-validation\n",
    "       class_weight='balanced',\n",
    "       tuner_name='RandomizedSearchCV',\n",
    "       columns_to_ignore=columns_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df = pd.DataFrame({'fold':[]})\n",
    "results_link_ids = cgc_outer.get_link_ids()[1]\n",
    "\n",
    "for fold in range(cgc_outer.get_n_splits()):\n",
    "    \n",
    "    test_links = results_link_ids[fold]\n",
    "    X_test_subset = X[X['link_ID'].isin(test_links)]#.drop(['community'], axis=1)\n",
    "    ml.set_fold_model(fold)\n",
    "    \n",
    "    y_proba = ml.predict_proba(X_test_subset)\n",
    "    df_len = len(y_proba)\n",
    "    results_fold_df = pd.DataFrame({\n",
    "        'fold':[fold]*df_len, \n",
    "        'link_ID':X_test_subset['link_ID'],\n",
    "        'type_train':[cgc_outer.groups_train]*df_len,\n",
    "        'type_test':[cgc_outer.groups_test]*df_len,\n",
    "        'frac_train':[cgc_outer.fractions_train]*df_len,\n",
    "        'frac_test':[cgc_outer.fractions_test]*df_len,\n",
    "        'model':[ml.model_name]*df_len,\n",
    "        'y_proba':y_proba,\n",
    "    })\n",
    "    results_df = pd.concat([results_df, results_fold_df], axis=0)\n",
    "\n",
    "results_df.to_csv(results_path+'/raw/results_lowDegBiasSampling.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transductive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "def transductive_learning(df):\n",
    "\n",
    "    # Split data\n",
    "    X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "    ## Set the training set\n",
    "    X_train = X.copy()\n",
    "    y_train = y.copy()\n",
    "\n",
    "    ## Set the test set\n",
    "    X_test = X.loc[y != 1]\n",
    "    y_test = y.loc[X_test.index]\n",
    "\n",
    "    # Avoid errors during fitting, happens when using cv in some cases\n",
    "    # X_train, y_train = X_train.reset_index(drop=True), y_train.reset_index(drop=True)\n",
    "\n",
    "    # Relabel links\n",
    "    y_train[y_train == -1] = 0\n",
    "    y_test[y_test == -1] = 1\n",
    "\n",
    "    # Set a transformer\n",
    "    preprocessor = LinkPredict().set_transformer(X_train, \n",
    "                                                columns_to_ignore=columns_ignore,\n",
    "                                                save=False,\n",
    "                                                return_preprocessor=True)\n",
    "\n",
    "    # RandomForestClassifier\n",
    "    param_dist = {\n",
    "        'feature_selector__k': [10, 20, 30, 40, 50],  # Number of features to select\n",
    "        'classifier__n_estimators': [int(x) for x in np.linspace(start = 5, stop = 100, num = 5)],\n",
    "        'classifier__max_features': ['sqrt', 'log2'],\n",
    "        'classifier__max_depth': [int(x) for x in np.linspace(10, 110, num = 11)] + [None],\n",
    "        'classifier__min_samples_split': [1 ,2, 3, 4, 5, 10],\n",
    "        'classifier__min_samples_leaf': [1, 2, 3, 4, 5, 10],\n",
    "        'classifier__max_samples': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "        'classifier__max_leaf_nodes': [2, 4, 8, 16, 32, 64, 128],\n",
    "        'classifier__bootstrap': [True, False],\n",
    "        'classifier__criterion': [\"gini\", \"entropy\"],\n",
    "    }\n",
    "    rf = RandomForestClassifier(n_jobs=-1, random_state=42, class_weight='balanced')\n",
    "\n",
    "    # Create pipeline\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"feature_selector\", SelectKBest(mutual_info_classif)),\n",
    "        (\"classifier\", rf)\n",
    "    ])\n",
    "\n",
    "    # RandomizedSearchCV\n",
    "    clf = RandomizedSearchCV(pipe, param_distributions=param_dist, scoring='f1', cv=3, random_state=42, n_jobs=-1)\n",
    "    clf.fit(X_train.reset_index(drop=True), y_train.reset_index(drop=True))\n",
    "\n",
    "    y_proba = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'link_ID':X_test['link_ID'],\n",
    "        'ML_single':y_proba,\n",
    "    })\n",
    "    return results_df\n",
    "    \n",
    "\n",
    "# Save results\n",
    "results_noBias = pd.DataFrame()\n",
    "results_highDegBias = pd.DataFrame()\n",
    "results_lowDegBias = pd.DataFrame()\n",
    "\n",
    "subsamples = df[(df['fraction'] == 0.8) & (df['community'].isin(['Plant-Pollinator', 'Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Herbivore']))]['subsample_ID'].unique()\n",
    "\n",
    "# Run random forest for each subsample\n",
    "for subsample in subsamples:\n",
    "    \n",
    "    print('Subsample:', subsample)\n",
    "\n",
    "    res_noBias = transductive_learning(df[df['subsample_ID'] == subsample])\n",
    "    res_highDegBias = transductive_learning(df_h[df_h['subsample_ID'] == subsample])\n",
    "    res_lowDegBias = transductive_learning(df_l[df_l['subsample_ID'] == subsample])\n",
    "\n",
    "    results_noBias = pd.concat([results_noBias, res_noBias], axis=0)\n",
    "    results_highDegBias = pd.concat([results_highDegBias, res_highDegBias], axis=0)\n",
    "    results_lowDegBias = pd.concat([results_lowDegBias, res_lowDegBias], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_noBias.to_csv(results_path+'/raw/results_transductiveML.csv', index=False)\n",
    "results_highDegBias.to_csv(results_path+'/raw/results_transductiveML_highDegBias.csv', index=False)\n",
    "results_lowDegBias.to_csv(results_path+'/raw/results_transductiveML_lowDegBias.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing network filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe\n",
    "meta_f, df_initial_f = load_data(\n",
    "    path_meta = 'data/processed/networks/filtering/subsamples_filtered_metadata.csv',\n",
    "    path_subsample = 'data/processed/networks/filtering/subsamples_filtered_edge_lists.csv',\n",
    "    paths_features = ['data/processed/features/filtering/features_filtered_py.csv',\n",
    "                      'data/processed/features/filtering/features_filtered_R.csv'],\n",
    ")\n",
    "\n",
    "df_f = df_initial_f.copy()\n",
    "\n",
    "to_drop = ['flow_infomap_HL', 'flow_infomap_LL', 'modular_centrality_infomap_HL', 'modular_centrality_infomap_LL']#,'discrepancy.HL', 'discrepancy.LL']\n",
    "df_f = df_f.drop(to_drop, axis=1)\n",
    "\n",
    "df_f['Fisher alpha'] = df_f['Fisher alpha'].astype('float64')\n",
    "df_f['class'] = df_f['class'].astype('int64')\n",
    "\n",
    "df_f = df_f[[c for c in df_f if c not in ['class']] + ['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f, y_f = LinkPredict().subset_data(df_f[(df_f['fraction']==0.8) & (df_f['class']!=1.0)], cast_target=True)\n",
    "\n",
    "results_f_df = pd.DataFrame({\n",
    "    'link_ID':X_f['link_ID'],\n",
    "    'y_proba':ml.predict_proba(X_f),\n",
    "})\n",
    "\n",
    "results_f_df.to_csv(results_path+'/raw/results_filtered_networks.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing sensitivity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe\n",
    "meta_s, df_initial_s = load_data(\n",
    "    path_meta = 'data/processed/networks/sensitivity/subsamples_sensitivity_metadata.csv',\n",
    "    path_subsample = 'data/processed/networks/sensitivity/subsamples_sensitivity_edge_lists.csv',\n",
    "    paths_features = ['data/processed/features/sensitivity/features_sensitivity_py.csv',\n",
    "                      'data/processed/features/sensitivity/features_sensitivity_R.csv'],\n",
    ")\n",
    "\n",
    "\n",
    "df_s = df_initial_s.copy()\n",
    "\n",
    "to_drop = ['flow_infomap_HL', 'flow_infomap_LL', 'modular_centrality_infomap_HL', 'modular_centrality_infomap_LL']#,'discrepancy.HL', 'discrepancy.LL']\n",
    "df_s = df_s.drop(to_drop, axis=1)\n",
    "\n",
    "df_s['Fisher alpha'] = df_s['Fisher alpha'].astype('float64')\n",
    "df_s['class'] = df_s['class'].astype('int64')\n",
    "\n",
    "df_s = df_s[[c for c in df_s if c not in ['class']] + ['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_list = [0.7,0.75,0.8,0.85,0.9,0.95]\n",
    "groups = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore']\n",
    "\n",
    "trained_models_sensitivity=[]\n",
    "cgc_list_sensitivity = []\n",
    "\n",
    "for frac in frac_list:\n",
    "  \n",
    "    print('Fraction:', frac)\n",
    "\n",
    "    # filter by fraction\n",
    "    X, y = LinkPredict().subset_data(df_s[(df_s['fraction']==frac) | (df_s['fraction']==1.0)], cast_target=False)\n",
    "\n",
    "    cgc_inner = CustomGroupCV(\n",
    "        group_by='name', \n",
    "        stratify_by='community', \n",
    "        fractions_col = 'fraction',\n",
    "        n_splits = 3,\n",
    "        fractions_train = [1],\n",
    "        fractions_test = [frac],\n",
    "        groups_train = groups,\n",
    "        groups_test = groups,\n",
    "        drop_isolates=False,\n",
    "        drop_existing_links = True\n",
    "        )\n",
    "\n",
    "    cgc_outer = CustomGroupCV(\n",
    "        group_by='name', \n",
    "        stratify_by='community', \n",
    "        fractions_col = 'fraction',\n",
    "        n_splits = 5,\n",
    "        fractions_train = [1],\n",
    "        fractions_test = [frac],\n",
    "        groups_train = groups,\n",
    "        groups_test = groups,\n",
    "        drop_isolates=False,\n",
    "        drop_existing_links = True,\n",
    "        keep_fractions_train=True, # Keep all fractions in train, although they are in fractions_train (will needed later)\n",
    "        keep_fractions_test=False\n",
    "        )\n",
    "    \n",
    "    ml = LinkPredict('RandomForestClassifier')\n",
    "\n",
    "    # Train\n",
    "    ml.fit(X,\n",
    "        y,\n",
    "        cv_inner=cgc_inner,\n",
    "        cv_outer=cgc_outer,\n",
    "        scorer_metric='f1',\n",
    "        class_weight='balanced',\n",
    "        tuner_name='RandomizedSearchCV',\n",
    "        columns_to_ignore=columns_ignore)\n",
    "\n",
    "    # Save model\n",
    "    trained_models_sensitivity.append(ml) \n",
    "    cgc_list_sensitivity.append(cgc_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_sensitivity = pd.DataFrame()\n",
    "\n",
    "for ml, cgc_outer in zip(trained_models_sensitivity, cgc_list_sensitivity):\n",
    "\n",
    "    results_link_ids = cgc_outer.get_link_ids()[1]\n",
    "\n",
    "    for fold in range(cgc_outer.get_n_splits()):\n",
    "        \n",
    "        test_links = results_link_ids[fold]\n",
    "        X_test_subset = df_s[df_s['link_ID'].isin(test_links)]\n",
    "        ml.set_fold_model(fold)\n",
    "        \n",
    "        y_proba = ml.predict_proba(X_test_subset)\n",
    "        df_len = len(y_proba)\n",
    "        results_fold_df = pd.DataFrame({\n",
    "            'fold':[fold]*df_len, \n",
    "            'link_ID':X_test_subset['link_ID'],\n",
    "            'frac_test':[cgc_outer.fractions_test[0]]*df_len,\n",
    "            'y_proba':y_proba,\n",
    "        })\n",
    "        results_sensitivity = pd.concat([results_sensitivity, results_fold_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sensitivity.to_csv(results_path+'/raw/results_sensitivity.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
