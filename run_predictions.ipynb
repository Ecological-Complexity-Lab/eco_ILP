{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base\n",
    "import os\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None) # turn off some annoying warnings\n",
    "\n",
    "# Number of avialable cores\n",
    "nslots = int(os.getenv('NSLOTS', 2))\n",
    "print('cores:' ,nslots, ', dir:', os.getcwd()) # should be '/gpfs0/shai/users/barryb/link-predict'\n",
    "\n",
    "# Force reload modules each execution\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load custom modules\n",
    "from helper.ml_class import LinkPredict\n",
    "from helper.ml_class import CustomGroupCV, CustomGroupSplit\n",
    "from helper.base import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe\n",
    "meta, df_initial = load_data(\n",
    "    path_meta = 'data/processed/networks/subsamples_metadata.csv',\n",
    "    path_subsample = 'data/processed/networks/subsamples_edge_lists.csv',\n",
    "    paths_features = ['data/processed/features/features_py.csv',\n",
    "                      'data/processed/features/features_R.csv'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = 'results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_initial.copy()\n",
    "\n",
    "# Drop features\n",
    "to_drop = ['density', \n",
    "           'common_neighbor_centrality',\n",
    "           'shortest_path_length', \n",
    "           'shortest_paths_count', \n",
    "           'flow_infomap_HL', \n",
    "           'flow_infomap_LL', \n",
    "           'modular_centrality_infomap_HL', \n",
    "           'modular_centrality_infomap_LL',\n",
    "           'discrepancy.HL', \n",
    "           'discrepancy.LL']\n",
    "df = df.drop(to_drop, axis=1, errors='ignore')\n",
    "\n",
    "df['Fisher alpha'] = df['Fisher alpha'].astype('float64')\n",
    "\n",
    "# TODO: Change this in the previuos steps as it is confusing\n",
    "df.loc[df['class'] == 'TN', 'class'] = 0\n",
    "df.loc[df['class'] == 'FN', 'class'] = -1\n",
    "df.loc[df['class'] == 'TP', 'class'] = 1\n",
    "df['class'] = df['class'].astype('int64')\n",
    "\n",
    "# Move 'class' to the end\n",
    "df = df[[c for c in df if c not in ['class']] + ['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgs = CustomGroupSplit(group_by='name', \n",
    "                       stratify_by='community', \n",
    "                       fractions_col = 'fraction',\n",
    "                       train_size=0.7, \n",
    "                       diff_range=None,\n",
    "                       fractions_train = [1],\n",
    "                       fractions_test = [0.8], \n",
    "                       stratify_groups_train = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "                       stratify_groups_test = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "                       drop_isolates=False,\n",
    "                       drop_existing_links = True,\n",
    "                       keep_fractions_train=True, # Keep all fractions in train, although they are in fractions_train (will needed later)\n",
    "                       keep_fractions_test=False,\n",
    "                       random_state=42,\n",
    "                       )\n",
    "\n",
    "train_idx, test_idx  = next(cgs.split(df))\n",
    "train_link_id, test_link_id  = cgs.get_link_ids(0)\n",
    "\n",
    "X_train, y_train = LinkPredict().subset_data(df, train_link_id, cast_target=False)\n",
    "X_test, y_test = LinkPredict().subset_data(df, test_link_id, cast_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgc_inner = CustomGroupCV(group_by='name', \n",
    "                    stratify_by='community', \n",
    "                    fractions_col = 'fraction',\n",
    "                    n_splits = 3,\n",
    "                    diff_range=None, \n",
    "                    fractions_train = [1],\n",
    "                    fractions_test = [0.8],\n",
    "                    stratify_groups_train = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "                    stratify_groups_test = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "                    drop_isolates=False,\n",
    "                    drop_existing_links = True,\n",
    "                    stratify_test_only_groups=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgc_outer = CustomGroupCV(group_by='name', \n",
    "                    stratify_by='community', \n",
    "                    fractions_col = 'fraction',\n",
    "                    n_splits = 5,\n",
    "                    diff_range=None, \n",
    "                    fractions_train = [1],\n",
    "                    fractions_test = [0.8],\n",
    "                    stratify_groups_train = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "                    stratify_groups_test = ['Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Pollinator', 'Plant-Herbivore'],\n",
    "                    drop_isolates=False,\n",
    "                    drop_existing_links = True,\n",
    "                    stratify_test_only_groups=False,\n",
    "                    keep_fractions_train=True, # Keep all fractions in train, although they are in fractions_train (will needed later)\n",
    "                    keep_fractions_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test split + Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml = LinkPredict('RandomForestClassifier')\n",
    "\n",
    "# ml.fit(X_train,\n",
    "#        y_train,\n",
    "#        dataset_link_id=train_link_id, # might not need this\n",
    "#        cv=cgc_inner,\n",
    "#        class_weight='balanced',\n",
    "#        tuner_name='RandomizedSearchCV',\n",
    "#        columns_to_ignore=['name', 'link_ID', 'subsample_ID', 'fraction', 'repetition', 'higher_level', 'lower_level', 'weight'])\n",
    "\n",
    "# ml.multi_plot(X_test, y_test, threshold=0.5, \n",
    "#     plots=['confusion_matrix', 'grouped_evaluation', 'roc_curve', 'pr_curve', 'probs_distribution', 'roc_curve_split', 'pr_curve_split', 'grouped_evaluation_split', 'feature_importance'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml = LinkPredict('RandomForestClassifier')\n",
    "# X, y = LinkPredict().subset_data(df, cast_target=False)\n",
    "\n",
    "# ml.fit(X,\n",
    "#        y,\n",
    "#        # dataset_link_id=train_link_id, # might not need this\n",
    "#        # cv=cgc_inner,\n",
    "#        cv_inner=cgc_inner,\n",
    "#        cv_outer=cgc_outer, # Nested cross-validation\n",
    "#        class_weight='balanced',\n",
    "#        tuner_name='RandomizedSearchCV',\n",
    "#        columns_to_ignore=['name', 'link_ID', 'subsample_ID', 'fraction', 'repetition', 'higher_level', 'lower_level', 'weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot feature importance\n",
    "# ml.plot_feature_importance(n=90)\n",
    "\n",
    "# # Plot permutation importance\n",
    "# ml.plot_permutation_importance(X_test, y_test, n_repeats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save results\n",
    "# results_df = pd.DataFrame({'fold':[]})\n",
    "# results_link_ids = cgc_outer.get_link_ids()[1]\n",
    "\n",
    "# for fold in range(cgc_outer.get_n_splits()):\n",
    "    \n",
    "#     test_links = results_link_ids[fold]\n",
    "#     X_test_subset = X[X['link_ID'].isin(test_links)]#.drop(['community'], axis=1)\n",
    "#     ml.set_fold_model(fold)\n",
    "    \n",
    "#     y_proba = ml.predict_proba(X_test_subset)\n",
    "#     df_len = len(y_proba)\n",
    "#     results_fold_df = pd.DataFrame({\n",
    "#         'fold':[fold]*df_len, \n",
    "#         'link_ID':test_links,\n",
    "#         'type_train':[cgc_outer.stratify_groups_train]*df_len,\n",
    "#         'type_test':[cgc_outer.stratify_groups_test]*df_len,\n",
    "#         'frac_train':[cgc_outer.fractions_train]*df_len,\n",
    "#         'frac_test':[cgc_outer.fractions_test]*df_len,\n",
    "#         'model':[ml.model_name]*df_len,\n",
    "#         'y_proba':y_proba,\n",
    "#     })\n",
    "#     results_df = pd.concat([results_df, results_fold_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.to_csv(results_path+'/raw/results_nested_cv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare all community types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Set netwrok types\n",
    "network_types = communities = [\n",
    "    'Host-Parasite', 'Plant-Pollinator', 'Plant-Seed Dispersers', 'Plant-Herbivore',\n",
    "]\n",
    "\n",
    "# Create combinations of network types for training and testing\n",
    "types_combinations = []\n",
    "for i in [1]: # remove last arg for all combs\n",
    "    types_combinations += list(combinations(network_types, i))\n",
    "\n",
    "types_combinations += [('Plant-Seed Dispersers', 'Plant-Pollinator', 'Plant-Herbivore', 'Host-Parasite')] # Ecological\n",
    "types_combinations+= [('Plant-Seed Dispersers', 'Plant-Herbivore', 'Host-Parasite')] # Ecological-Non-Plant-Pollinator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models_types=[]\n",
    "cgc_list = []\n",
    "\n",
    "for types_train in types_combinations:\n",
    "    for types_test in types_combinations:\n",
    "        \n",
    "        print('Type train:', types_train, '\\nType test:', types_test, '\\n')\n",
    "        \n",
    "        cgc_inner = CustomGroupCV(group_by='name', \n",
    "                            stratify_by='community', \n",
    "                            fractions_col = 'fraction',\n",
    "                            n_splits = 3,\n",
    "                            diff_range=None, \n",
    "                            fractions_train = [1],\n",
    "                            fractions_test = [0.8],\n",
    "                            stratify_groups_train = types_train,\n",
    "                            stratify_groups_test = types_test,\n",
    "                            drop_isolates=False,\n",
    "                            drop_existing_links = True,\n",
    "                            stratify_test_only_groups=False)\n",
    "        \n",
    "        cgc_outer = CustomGroupCV(group_by='name', \n",
    "                            stratify_by='community', \n",
    "                            fractions_col = 'fraction',\n",
    "                            n_splits = 5,\n",
    "                            diff_range=None, \n",
    "                            fractions_train = [1],\n",
    "                            fractions_test = [0.8],\n",
    "                            stratify_groups_train = types_train,\n",
    "                            stratify_groups_test = types_test,\n",
    "                            drop_isolates=False,\n",
    "                            drop_existing_links = True,\n",
    "                            stratify_test_only_groups=False,\n",
    "                            keep_fractions_train=True, # Keep all fractions in train, although they are in fractions_train (will needed later)\n",
    "                            keep_fractions_test=False)\n",
    "\n",
    "        ml = LinkPredict('RandomForestClassifier')\n",
    "\n",
    "        X, y = LinkPredict().subset_data(df, cast_target=False)\n",
    "\n",
    "        # Train\n",
    "        ml.fit(X,\n",
    "            y,\n",
    "            cv_inner=cgc_inner,\n",
    "            cv_outer=cgc_outer,\n",
    "            class_weight='balanced',\n",
    "            tuner_name='RandomizedSearchCV',\n",
    "            columns_to_ignore=['name', 'link_ID', 'subsample_ID', 'fraction', 'repetition', 'higher_level', 'lower_level', 'weight'])\n",
    "\n",
    "        # Save model\n",
    "        ml.types_train = types_train\n",
    "        ml.types_test = types_test\n",
    "        trained_models_types.append(ml) \n",
    "        cgc_list.append(cgc_outer)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df = pd.DataFrame() #{'fold':[]}\n",
    "\n",
    "for ml, cgc_outer in zip(trained_models_types, cgc_list):\n",
    "\n",
    "    results_link_ids = cgc_outer.get_link_ids()[1]\n",
    "\n",
    "    for fold in range(cgc_outer.get_n_splits()):\n",
    "\n",
    "        test_links = results_link_ids[fold]\n",
    "        X_test_subset = X[X['link_ID'].isin(test_links)]\n",
    "        ml.set_fold_model(fold)\n",
    "        \n",
    "        y_proba = ml.predict_proba(X_test_subset)\n",
    "        df_len = len(y_proba)\n",
    "        results_run_df = pd.DataFrame({\n",
    "            'fold':[fold]*df_len, \n",
    "            'link_ID':test_links,\n",
    "            'type_train':[list(cgc_outer.stratify_groups_train)]*df_len,\n",
    "            'type_test':[list(cgc_outer.stratify_groups_test)]*df_len,\n",
    "            # 'frac_train':[cgc_outer.fractions_train]*df_len,\n",
    "            # 'frac_test':[cgc_outer.fractions_test]*df_len,\n",
    "            # 'model':[ml.model_name]*df_len,\n",
    "            'y_proba':y_proba,\n",
    "        })\n",
    "        results_df = pd.concat([results_df, results_run_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(results_path+'/raw/results_domains.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare ML algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting important variables\n",
    "communities = ['Host-Parasite', 'Plant-Pollinator', 'Plant-Seed Dispersers', 'Plant-Herbivore']\n",
    "classifiers = ['RandomForestClassifier', 'LogisticRegression', 'XGBClassifier']\n",
    "\n",
    "# Store trained models in a list\n",
    "trained_models_algos=[]\n",
    "cgc_list = []\n",
    "\n",
    "# Iterate over classifiers\n",
    "for clf_name in classifiers:\n",
    "\n",
    "   print('Classifier:', clf_name)\n",
    "    \n",
    "   cgc_inner = CustomGroupCV(group_by='name', \n",
    "                  stratify_by='community', \n",
    "                  fractions_col = 'fraction',\n",
    "                  n_splits = 3,\n",
    "                  diff_range=None, \n",
    "                  fractions_train = [1],\n",
    "                  fractions_test = [0.8],\n",
    "                  stratify_groups_train = communities,\n",
    "                  stratify_groups_test = communities,\n",
    "                  drop_isolates=False,\n",
    "                  drop_existing_links = True,\n",
    "                  stratify_test_only_groups=False)\n",
    "\n",
    "   cgc_outer = CustomGroupCV(group_by='name', \n",
    "                    stratify_by='community', \n",
    "                    fractions_col = 'fraction',\n",
    "                    n_splits = 5,\n",
    "                    diff_range=None, \n",
    "                    fractions_train = [1],\n",
    "                    fractions_test = [0.8],\n",
    "                    stratify_groups_train = communities,\n",
    "                    stratify_groups_test = communities,\n",
    "                    drop_isolates=False,\n",
    "                    drop_existing_links = True,\n",
    "                    stratify_test_only_groups=False,\n",
    "                    keep_fractions_train=True, # Keep all fractions in train, although they are in fractions_train (will needed later)\n",
    "                    keep_fractions_test=False)\n",
    "   \n",
    "   ml = LinkPredict(clf_name) # Initialize model\n",
    "\n",
    "   X, y = LinkPredict().subset_data(df, cast_target=False)\n",
    "   \n",
    "   ml.fit(X,\n",
    "      y,\n",
    "      cv_inner=cgc_inner,\n",
    "      cv_outer=cgc_outer, # Nested cross-validation\n",
    "      class_weight='balanced',\n",
    "      tuner_name='RandomizedSearchCV',\n",
    "      columns_to_ignore=['name', 'link_ID', 'subsample_ID', 'fraction', 'repetition', 'higher_level', 'lower_level', 'weight'])\n",
    "\n",
    "   trained_models_algos.append(ml) # Save model\n",
    "   cgc_list.append(cgc_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for ml, cgc_outer in zip(trained_models_algos, cgc_list):\n",
    "\n",
    "    results_link_ids = cgc_outer.get_link_ids()[1]\n",
    "\n",
    "    for fold in range(cgc_outer.get_n_splits()):\n",
    "\n",
    "        test_links = results_link_ids[fold]\n",
    "        # X_test_subset = X[X['link_ID'].isin(test_links)]\n",
    "        X_test_subset, y_test_subset = ml.subset_data(df, test_links)\n",
    "        ml.set_fold_model(fold)\n",
    "\n",
    "        y_proba = ml.predict_proba(X_test_subset)\n",
    "        df_len = len(y_proba)\n",
    "\n",
    "        results_run_df = pd.DataFrame({\n",
    "            'fold':[fold]*df_len,\n",
    "            'link_ID':test_links,\n",
    "            'model':[ml.model_name]*df_len,\n",
    "            'y_proba':y_proba,\n",
    "        })\n",
    "\n",
    "        results_df = pd.concat([results_df, results_run_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting\n",
    "voting_df = results_df.groupby(['fold', 'link_ID'])['y_proba'].mean().reset_index() # Compute the mean values\n",
    "voting_df['model'] = 'Voting'\n",
    "results_df = pd.concat([results_df, voting_df], axis=0) # Merge with the original DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(results_path+'/raw/results_models.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "params_df = pd.DataFrame()\n",
    "\n",
    "for ml, cgc_outer in zip(trained_models_algos, cgc_list):\n",
    "    for fold in range(cgc_outer.get_n_splits()):\n",
    "        ml.set_fold_model(fold)\n",
    "\n",
    "        best_params = ml.trained_model.best_params_\n",
    "        params_df = pd.concat([params_df, \n",
    "                               pd.DataFrame({'model':[ml.model_name], \n",
    "                                             'fold':[fold], \n",
    "                                             'params':[best_params], \n",
    "                                             'params_dist':[ml.params_dist]})], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distbribution and best parameters for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to collect data\n",
    "data = {}\n",
    "\n",
    "for ml, cgc_outer in zip(trained_models_algos, cgc_list):\n",
    "    # Initialize a sub-dictionary for each model\n",
    "    model_data = {}\n",
    "    \n",
    "    for fold in range(cgc_outer.get_n_splits()):\n",
    "        ml.set_fold_model(fold)\n",
    "\n",
    "        best_params = ml.trained_model.best_params_\n",
    "        \n",
    "        # Update model_data with fold information for each parameter\n",
    "        for param, best_value in best_params.items():\n",
    "            simple_param = param.replace('classifier__', '')\n",
    "            \n",
    "            if simple_param not in model_data:\n",
    "                model_data[simple_param] = {'model': ml.model_name, 'parameter': simple_param}\n",
    "            \n",
    "            # Adding the best value for each fold\n",
    "            model_data[simple_param][f'best value (fold {fold + 1})'] = best_value\n",
    "\n",
    "    # Add model data to the main data dictionary, handling params_dist separately\n",
    "    for param, values in model_data.items():\n",
    "        # Extract range for this parameter from params_dist (handle both dict and list of dicts)\n",
    "        params_dist = ml.params_dist\n",
    "        if isinstance(params_dist, list):  # If params_dist is a list of dictionaries\n",
    "            param_range = [d.get(param) for d in params_dist if param in d][0]\n",
    "        else:  # If params_dist is a dictionary\n",
    "            param_range = params_dist.get(param)\n",
    "        \n",
    "        values['range'] = param_range\n",
    "        data[(ml.model_name, param)] = values\n",
    "\n",
    "# Convert the collected data into a DataFrame\n",
    "params_df = pd.DataFrame.from_dict(data, orient='index').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df.to_csv(results_path+'/raw/params_models.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance_all_df = pd.DataFrame()\n",
    "\n",
    "for fold in range(cgc_outer.get_n_splits()):\n",
    "    for ml in trained_models_algos:\n",
    "        ml.set_fold_model(fold)\n",
    "        feat_importance_df = ml.feature_importance(X_train=X_train).to_frame(ml.model_name).reset_index().rename(columns={'index':'feature'}).melt(id_vars='feature', var_name='model', value_name='importance')\n",
    "        feat_importance_df['fold'] = fold\n",
    "        feat_importance_all_df = pd.concat([feat_importance_all_df, feat_importance_df], axis=0)\n",
    "\n",
    "feat_importance_all_df.reset_index(drop=True).to_csv(results_path+\"/raw/feature_importance_nCV.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transductive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "res = []\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "subsamples = df[(df['fraction'] == 0.8) & (df['community'].isin(['Plant-Pollinator', 'Plant-Seed Dispersers', 'Host-Parasite', 'Plant-Herbivore']))]['subsample_ID'].unique()\n",
    "\n",
    "# Run random forest for each subsample\n",
    "for subsample in subsamples:\n",
    "    \n",
    "    print('Subsample:', subsample)\n",
    "    \n",
    "    # Subset data\n",
    "    df_subsample = df[df['subsample_ID'] == subsample]\n",
    "\n",
    "    # Feature selection\n",
    "    \n",
    "\n",
    "    # Split data\n",
    "    X, y = df_subsample.iloc[:,:-1], df_subsample.iloc[:,-1]\n",
    "\n",
    "    ## Set the training set\n",
    "    X_train = X.copy()\n",
    "    y_train = y.copy()\n",
    "\n",
    "    ## Set the test set\n",
    "    X_test = X.loc[y != 1]\n",
    "    y_test = y.loc[X_test.index]\n",
    "\n",
    "    # Avoid errors during fitting, happens when using cv in some cases\n",
    "    # X_train, y_train = X_train.reset_index(drop=True), y_train.reset_index(drop=True)\n",
    "\n",
    "    # Relabel links\n",
    "    y_train[y_train == -1] = 0\n",
    "    y_test[y_test == -1] = 1\n",
    "\n",
    "    # Set a transformer\n",
    "    preprocessor = LinkPredict().set_transformer(X_train, \n",
    "                                                columns_to_ignore=['name', 'link_ID', 'subsample_ID', 'fraction', 'repetition', 'higher_level', 'lower_level', 'weight'],\n",
    "                                                save=False,\n",
    "                                                return_preprocessor=True)\n",
    "\n",
    "    # RandomForestClassifier\n",
    "    param_dist = {\n",
    "        'n_estimators': [int(x) for x in np.linspace(start = 5, stop = 100, num = 5)],\n",
    "        'max_features' : ['sqrt', 'log2'],\n",
    "        'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)] + [None],\n",
    "        'min_samples_split': [1 ,2, 3, 4, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 3, 4, 5, 10],\n",
    "        'max_samples': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "        'max_leaf_nodes': [2, 4, 8, 16, 32, 64, 128],\n",
    "        'bootstrap': [True, False],\n",
    "        'criterion' : [\"gini\", \"entropy\"],\n",
    "    }\n",
    "    param_dist = {f'classifier__{k}': v for k, v in param_dist.items()} # Rename each key in the dictionary to 'classifier__' + key\n",
    "    rf = RandomForestClassifier(n_jobs=-1, random_state=42, class_weight='balanced')\n",
    "\n",
    "    # Create pipeline\n",
    "    pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), \n",
    "                            (\"classifier\", rf)])\n",
    "\n",
    "    # RandomizedSearchCV\n",
    "    clf = RandomizedSearchCV(pipe, param_distributions=param_dist, scoring='f1', cv=3, random_state=42, n_jobs=-1)\n",
    "    clf.fit(X_train.reset_index(drop=True), y_train.reset_index(drop=True))\n",
    "\n",
    "    res.append(clf)\n",
    "\n",
    "    y_proba = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    results_single_df = pd.DataFrame({\n",
    "        'link_ID':X_test['link_ID'],\n",
    "        'ML_single':y_proba,\n",
    "    })\n",
    "\n",
    "    results_df = pd.concat([results_df, results_single_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(results_path+'/raw/results_ML_by_single_networks.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
