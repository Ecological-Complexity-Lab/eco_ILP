{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from tqdm import tqdm # Progress Bar\n",
    "\n",
    "from helper.networks_functions import load_networks, create_samples, export2csv\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum and maximum size of networks to keep\n",
    "minNetworkSize = 20\n",
    "maxNetworkSize = 1000\n",
    "\n",
    "minConnectance = 0.1\n",
    "\n",
    "# List of desired fractions ('1' is automatically included)\n",
    "frac_list = [0.8] #[0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Number of subsamples to generate\n",
    "subsamples_reps = 1\n",
    "\n",
    "# Subsample multiple times, take to one with the lowest components\n",
    "min_components = False,\n",
    "\n",
    "# Path to the networks folder to import\n",
    "# WOL_path = 'data/networks/Web Of Life/**/*.csv'\n",
    "Brimacombe_path = 'data/networks/topological_heterogeneity_upload/networks/*.txt'\n",
    "\n",
    "# Path to the output file\n",
    "output_dir = 'data/processed/'\n",
    "\n",
    "weighted = False # currently the code is supporting only unweighted\n",
    "\n",
    "# Unwanted communities to drop\n",
    "ignored_communities = ['Journal', 'Microbiome', 'Actor', 'Plant-Ant', 'Food-Web', 'Multiples', 'Anemone-Fish',\n",
    "                       'Legislature', 'Chicago', 'Denver', 'Minneapolis', 'San Francisco', 'Washington',\n",
    "                       'Baseball', 'Basketball', 'Hockey']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import networks from Brimacombe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the databases | (Brimacombe's data)\n",
    "networks = load_networks(Brimacombe_path, ignored_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the databases | (Web Of Life)\n",
    "# networks_new = load_wol(WOL_path, rename_communities, symbiotic_relationships, columns_rows_drop, ignored_communities, transpose_list)\n",
    "# networks.update(networks_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for net_id, net_data in tqdm(networks.copy().items(), desc='Processing and subsampling'):\n",
    "    \n",
    "    # Loop each layer/monolayer network\n",
    "    for layer in net_data[\"Network_Layers\"].copy():\n",
    "        \n",
    "        adj_matrix = net_data[\"Network_Layers\"][layer]['Adjacency_Matrix']\n",
    "        edge_list = net_data[\"Network_Layers\"][layer]['Edge_List'] # TODO: both forms are not needed, drop one\n",
    "        \n",
    "        # Drop small/large networks\n",
    "        if sum(adj_matrix.shape)<minNetworkSize or sum(adj_matrix.shape)>maxNetworkSize:\n",
    "            del networks[net_id][\"Network_Layers\"][layer]\n",
    "            continue\n",
    "        # Drop networks with low connectance\n",
    "        connectance = np.count_nonzero(adj_matrix) / (adj_matrix.shape[0] * adj_matrix.shape[1])\n",
    "        if connectance < minConnectance:\n",
    "            del networks[net_id][\"Network_Layers\"][layer]\n",
    "            continue\n",
    "        \n",
    "        # Generate subsamples\n",
    "        sample = create_samples(adj_matrix, edge_list, frac_list, reps = subsamples_reps, weighted = weighted, min_components = min_components)\n",
    "        net_data[\"Network_Layers\"][layer][\"Subsamples\"].update(sample)\n",
    "        \n",
    "    # Drop empty networks (might result when all layers dosn't meet the defined requirements)\n",
    "    if len(networks[net_id][\"Network_Layers\"]) == 0:\n",
    "        del networks[net_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the edgelists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export2csv(networks, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
